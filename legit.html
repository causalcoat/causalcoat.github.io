<!DOCTYPE html>
<!-- TypeIt package -->
<script src="https://code.jquery.com/jquery-3.0.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/jquery.typeit/4.4.0/typeit.min.js"></script>
<html>
    <head>
        <meta charset="utf-8">
        <meta name="description" content="Can Large Language Models Help Experimental Design for Causal Discovery?">
        <meta name="keywords" content="JailBreak, LLM, Security">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>Can Large Language Models Help Experimental Design for Causal Discovery?</title>
        <!-- Google tag (gtag.js) -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-MK2R9XDD88"></script>
        <script>
            window.dataLayer = window.dataLayer || [];
            function gtag() { dataLayer.push(arguments); }
            gtag('js', new Date());

            gtag('config', 'G-MK2R9XDD88');
        </script>
        <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
        <link rel="stylesheet" href="./static/css/bulma.min.css">
        <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
        <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
        <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
        <link rel="stylesheet" href="./static/css/index.css">
        <link rel="icon" href="./static/images/causalcoat.webp">
        <link rel="stylesheet" href="./static/css/project-nav.css"> 


        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <script defer src="./static/js/fontawesome.all.min.js"></script>
        <script src="./static/js/bulma-carousel.min.js"></script>
        <script src="./static/js/bulma-slider.min.js"></script>
        <script src="./static/js/index.js"></script>
        
        <!-- Typing Effect JS -->
        <script src="https://code.jquery.com/jquery-3.0.0.min.js"></script>
        <script src="https://cdn.jsdelivr.net/jquery.typeit/4.4.0/typeit.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/typeit/5.10.1/typeit.min.js"></script>
        <!-- / Typing Effect JS -->
        <style>
            .bigdiv {
                font-size: large;
                font-family: "Courier New";
                padding: 2rem;
            }
            p {
                padding: 2rem;
            }
        </style>

        <!-- 添加导航脚本 -->
        <script src="./static/js/project-nav.js"></script>
    </head>
    <body>
        <section class="hero">
            <div class="hero-body">
                <div class="container is-max-desktop">
                    <div class="columns is-centered">
                        <div class="column has-text-centered">
                            <h1 class="title is-1 publication-title">Can Large Language Models Help Experimental Design for Causal Discovery?</h1>
                            <div class="is-size-5 publication-authors">
                                <span class="author-block">
                                    <a href="https://terrylee77.github.io/">Junyi Li</a>
                                    <sup>1*</sup>
                                    ,
                                </span>
                                <span class="author-block">
                                    <a href="https://lfhase.win">Yongqiang Chen</a>
                                    <sup>2,3*</sup>
                                    ,
                                </span>
                                <span class="author-block">
                                    <a href="https://chxliou.github.io/">Chenxi Liu</a>
                                    <sup>4</sup>
                                    ,
                                </span>
                                <span class="author-block">
                                    <a href="">Qianyi Cai</a>
                                    <sup>1</sup>
                                    ,
                                </span>
                                <br>
                                <span class="author-block">
                                    <a href="https://tongliang-liu.github.io/">Tongliang Liu</a>
                                    <sup>5,2</sup>
                                    ,
                                </span>
                                <span class="author-block">
                                    <a href="https://bhanml.github.io/">Bo Han</a>
                                    <sup>4</sup>
                                    ,
                                </span>
                                <span class="author-block">
                                    <a href="https://www.andrew.cmu.edu/user/kunz1/index.html">Kun Zhang</a>
                                    <sup>2,3</sup>
                                    ,
                                </span>
                                <span class="author-block">
                                    <a href="https://scholar.google.com/citations?hl=en&user=cVDF1tkAAAAJ&view_op=list_works&sortby=pubdate">Hui Xiong</a>
                                    <sup>1</sup>
                                    ,
                                </span>
                            </div>
                            <div class="is-size-5 publication-authors">
                                <span class="author-block">
                                    <sup>1</sup>The Hong Kong University of Science and Technology (Guangzhou),
                                </span>
                                <br>
                                <span class="author-block">
                                    <sup>2</sup>MBZUAI,
                                </span>
                                <span class="author-block">
                                    <sup>3</sup>Carnegie Mellon University
                                </span>
                                <span class="author-block">
                                    <sup>4</sup>Hong Kong Baptist University,
                                </span>
                                <span class="author-block">
                                    <sup>5</sup>The University of Sydney,
                                </span>
                            </div>
                            <div class="is-size-5 publication-authors">
                                <span class="author-block" style="font-size: 15px;">(
                                    <sup>*</sup>Equal Contribution)
                                </span> 
                            </div>
                            <div class="column has-text-centered">
                                <div class="publication-links">
                                    <!-- PDF Link. -->
                                    <span class="link-block">
                                        <a href="https://arxiv.org/abs/2503.01139" class="external-link button is-normal is-rounded is-dark">
                                            <span class="icon">
                                                <i class="fas fa-file-pdf"></i>
                                            </span>
                                            <span>Paper</span>
                                        </a>
                                    </span>
                                    <!-- Code Link. -->
                                    <span class="link-block">
                                        <a href="https://causalcoat.github.io/legit.html" class="external-link button is-normal is-rounded is-dark">
                                            <span class="icon">
                                                <i class="fab fa-github"></i>
                                            </span>
                                            <span>Code</span>
                                        </a>
                                    </span>
                                </div>
                            </div>
                            <!-- <div style="color: rgb(32, 64, 128);">
                                <i>Accepted at <a style="color: rgb(32, 64, 128);font-weight: bold; text-decoration: underline;" href="https://neurips.cc/virtual/2024/poster/93175">NeurIPS 2024</a></i>
                            </div> -->
                        </div>
                    </div>
                </div>
            </section>
            <!-- <div class="content has-text-centered">
              <img src="./static/images/causalcoat.webp" style="width:200px;">
            </div> -->
            <section class="section">
                <div class="container is-max-desktop">
                    <!-- Abstract. -->
                    <div class="columns is-centered has-text-centered">
                        <div class="column is-four-fifths">
                            <h2 class="title is-3">Abstract</h2>
                            <div class="content has-text-justified">
                                <p>
                                    Designing proper experiments and selecting optimal intervention targets is a longstanding problem in scientific or causal discovery. 
                                    Identifying the underlying causal structure from observational data alone is inherently difficult. Obtaining interventional data, on the other hand, is crucial to causal discovery, yet it is usually expensive and time-consuming to gather sufficient interventional data to facilitate causal discovery. 
                                    Previous approaches commonly utilize uncertainty or gradient signals to determine the intervention targets. 
                                    However, numerical-based approaches may yield suboptimal results due to the inaccurate estimation of the guiding signals at the beginning when with limited interventional data. 
                                    In this work, we investigate a different approach, whether we can leverage Large Language Models (LLMs) to assist with the intervention targeting in causal discovery by making use of the rich world knowledge about the experimental design in LLMs. 
                                    Specifically, we present Large Language Model Guided Intervention Targeting (LeGIT) -- a robust framework that effectively incorporates LLMs to augment existing numerical approaches for the intervention targeting in causal discovery. 
                                    Across 4 realistic benchmark scales, LeGIT demonstrates significant improvements and robustness over existing methods and even surpasses humans, which demonstrates the usefulness of LLMs in assisting with experimental design for scientific discovery.
                                </p>
                            </div>
                        </div>
                    </div>
                    <!--/ Abstract. -->
                </div>
            </section>
            
            <section class="section">
                <div class="container is-max-desktop">
                    <!-- Abstract. -->
                    <div class="columns is-centered has-text-centered">
                        <div class="column is-four-fifths">
                            <h2 class="title is-3">LeGIT Framework</h2>
                            <div class="content has-text-justified">
                                <!-- Add image -->
                                <div class="figure" style="align: left; text-align:center;">
                                    <img
                                        src="./static/paper_imgs/LeGIT/LeGIT_V5.png"
                                        alt="img description"
                                        style="max-width: 100%; height: auto;"
                                    >
                                    <p class="content is-centered" style="color: gray; font-size: 10pt;">
                                        <b>Figure 1</b>. Illustration of the LeGI framework.
                                    </p>
                                </div>
The left side represents the loop of Online Causal Discovery, while the right side illustrates the experiment design process. 
In Step (a), Large Language Models (LLMs) warm up the causal discovery process by leveraging world knowledge and aligning it with the experiment's meta-information. 
This enables the identification of clear causal structures, which, in Step (b), guide previous methods to pinpoint informative intervention targets effectively.
                            </p>
                        </div>
                    </div>
                </div>
                <!--/ Abstract. -->
            </div>
        </section>
        <section class="section">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column is-full-width has-text-centered">
                        <h2 class="title is-3">Challenges in Existing Intervention Targeting</h2>
                        <br>
                        <div class="content  has-text-justified">
                            <img
                                src="./static/paper_imgs/LeGIT/epoch3.png"
                                style="width:800px;"
                                style="max-width: 100%; height: auto;"
                            >
                            <p class="content is-centered" style="color: gray; font-size: 10pt;">
                                <b>Figure 2</b>. At the initial stage of the online causal discovery, the intervention targets from LLM-based selection and
                                gradient-based selection.
                            </p>
                            <div class="content has-text-centered">
                                <img
                                    src="./static/paper_imgs/LeGIT/prompt.png"
                                    style="width:600px;"
                                    class="result-image"
                                    alt="Interpolation end reference image."
                                >
                                <p class="content is-centered" style="color: gray; font-size: 10pt;">
                                    <b>Box 1</b>. Prompt template at warmup stage.
                                </p>
                            </div>
Intuitively, at the beginning of the intervention, intervening on variables that affect lots of other variables can bring more information about the system. 
For numerical methods, in the Asia, Alarm dataset, the selected intervention targets are influential nodes. However, in insurance, the selected nodes only influence a few other nodes. 
Intervening on such targets with limited influence may lead to significant resource waste and further misdirect subsequent online causal discovery rounds. 
In contrast, we construct prompts to inquire LLMs about the root causes in this system, given only the meta-information  such as simple variable descriptions. The specific prompts are given in Box 1, and the suggested intervening targets are
also highlighted in Fig. 2. It can be found that given only the meta-information, LLMs are able to relate the rich world  knowledge to locate the desired influential nodes.
                        </div>              
        </section>
        <section class="section">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column is-full-width has-text-centered">
                        <h2 class="title is-3">Results on Realistic Benchmarks</h2>
                        <div class="content has-text-justified is-centered">
                            <p>
We evaluate LeGIT on four realistic causal discovery benchmarks: Asia, Child, Insurance, and Alarm. We compare LeGIT against different online causal discovery algorithms GIT, AIT, CBED as selection strategies for online active learning interventions, as well as three random baselines and human baseline.
                            </p>
                        </div>
                        <div class="content has-text-centered">
                            <img
                                src="./static/paper_imgs/LeGIT/table1.png"
                                style="max-width: 100%; height: auto;"
                            >
                            <p class="content is-centered" style="color: gray; font-size: 10pt;">
                                <b>Table 1</b>. Average SHD, SID, and BSF with standard deviation (over 5 seeds) for real-world data (T = 33 rounds,|D<sub>int</sub>| = 32,N = 1056).
                            </p>
                        </div>
                        <div class="content has-text-justified is-centered">
                            <img
                                src="./static/paper_imgs/LeGIT/result_V3.png"
                                style="max-width: 100%; height: auto;"
                            >
                            <p class="content is-centered" style="color: gray; font-size: 10pt;">
                                <b>Figure 3</b>. SHD metric for different methods (over 5 seeds) towards different intervention samples (T = 33 rounds,|D<sub>int</sub>| = 32,N = 1056).
                            </p>
                            <b>Main Result:</b>
                                    LeGIT achieves state-of-the-art causal discovery performances, with consistent improvements against the adopted gradient-based methods and human baseline.
                                    The superior SHD (Structural Hamming Distance) scores indicate that LeGIT reconstructs causal graphs more accurately, requiring fewer erroneous edge modifications.
                                    The SID (Structural Intervention Distance) results highlight LeGIT's robustness in preserving causal relationships, ensuring reliable causal inferences, which is crucial for real-world applications. 
                                    Additionally, the BSF metric demonstrates that LeGIT produces graphs that more accurately reflect true causal structures.
                                    As shown in Figure 3, while LeGIT initially does not perform optimally in online causal discovery, it quickly converges to a superior solution as more intervention data becomes available. 
                                    In contrast, GIT, despite a faster initial improvement, ultimately converges to a suboptimal solution due to poor initialization.

                        </div>
                        <br>
                        <div class="content has-text-justified is-centered">
                            <img
                                src="./static/paper_imgs/LeGIT/table2.png"
                                style="max-width: 100%; height: auto;"
                            >
                            <p class="content is-centered" style="color: gray; font-size: 10pt;">
                                <b>Table 2</b>. Average SHD, SID, and BSF with standard deviation (over 5 seeds) for real-world data with a low data budget (T = 33 rounds,|D<sub>int</sub>| = 16,N = 528).
                            </p>
                            <b>LowDataExperiment Analysis:</b>
                                This low-data setting is more practically relevant. 
                                Additionally, due to the insufficient intervention data, the performance of causal discovery algorithms in estimating effects is diminished, which further tests the effectiveness of the intervention strategy.
                                Table 2, show that LeGIT achieves larger improvements under these conditions in 3 complex  datasets. 
                                These findings highlight the effectiveness of LeGIT in real-world experimental design scenarios, where both the number of interventions and the sample size are limited.
                                The result of the low-data experiment further verifies our discussion that numerical methods suffer from noise or insufficient data, leading to a suboptimal solution. 
                                the use of LLMs enables scalable and effective guidance that complements numerical methods, reducing the risk of suboptimal convergence, and having more stable performance in real-world applications.

                        </div>
                        <br>
                        <div class="content has-text-justified is-centered">
                            <img
                                src="./static/paper_imgs/LeGIT/epoch_5.png"
                                style="max-width: 100%; height: auto;"
                            >
                            <p class="content is-centered" style="color: gray; font-size: 10pt;">
                                <b>Figure 4</b>. The selected Node Frequency obtained by different strategies on Epoch 0-4 from 5 different seeds under Table1 setting.
                            </p>
                            <b>Detailed comparisons and analyses:</b>
                                Figures 4 illustrate the distribution of selected nodes over the first five epochs. 
                                Numerical methods like GIT and AIT struggle during initialization, frequently selecting peripheral or leaf nodes in datasets like Insurance and Alarm, leading to suboptimal interventions. 
                                In contrast, LeGIT effectively identifies central and influential nodes, such as SocioEcon in the Insurance dataset, which plays a key role in determining car choice, driving behavior, and safety affordability.
                                Compared to the Human baseline, LeGIT outperforms in complex datasets (Alarm and Insurance), particularly when dealing with a large number of variables, where finding optimal interventions becomes computationally challenging.
                                Human experts may exhibit subjective biases or oversimplified mental models, making the process tedious and error-prone.
                                Additionally, LLMs (as referenced in Figures 1) provide a systematic and scalable approach by following structured prompts and leveraging background knowledge. 
                                With the self-consistency prompt technique, LLMs generate more robust and reliable results, serving as a cost-effective alternative to multiple human experts.
                                The primary advantage of LLMs lies in scalability and real-time availability, particularly for online causal discovery, where rapid interventions are required. 
                                They excel in large-scale systems where human experts cannot manually assess all variables. 
                                By complementing human oversight, LLMs help reduce biases, improve consistency, and accelerate metadata processing, ultimately saving experts time and providing a solid foundation for causal discovery.

                        </div>
                        <br>
                    </div>
                </div>
            </div>
        </section>
        <section class="section">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column is-full-width has-text-centered">
                        <h2 class="title is-3">Conclusion</h2>
                        <div class="content has-text-justified">
                            <p>
                                In this work, we investigated how to incorporate LLMs into the intervention targeting in experimental design for causal
                                discovery. We introduced a novel framework called LeGIT, which combines the best of previous numerical-based
                                approaches and the rich knowledge in LLMs. Specifically, LeGIT leverages LLMs to warm up the online causal
                                discovery procedure by identifying the influential root cause variables to begin the intervention. After setting up a
                                relatively clear picture of the underlying causal graph, LeGIT then integrates the numerical-based methods to continue
                                to select the intervention targets. Empirically, we verified the effectiveness of LeGIT leveraging LLMs to warm up
                                the online causal discovery can achieve the state-of-the-art performance across multiple realistic causal discovery
                                benchmarks. Furthermore, we compared its performance against a human baseline, highlighting its unique value. LLMs
                                offer a scalable and cost-effective approach to enhance experimental design, paving the way for new research directions
                                of causal analysis and scientific discovery fields.
                            </p>
                    </div>
                </div>
            </div>
        </section>
        <section class="section" id="BibTeX">
            <div class="container is-max-desktop content">
                <h2 class="title">Contact</h2>
                <p>
                    Welcome to check our paper for more details of the research work. For any question, please feel free to contact us.
                </p>
                <p>
                    If you find our paper and repo useful, please consider to cite:
                </p>
                <pre>
                    <code>
@inproceedings{Li2025CanLL,
    title={Can Large Language Models Help Experimental Design for Causal Discovery?},
    author={Junyi Li and Yongqiang Chen and Chenxi Liu and Qianyi Cai and Tongliang Liu and Bo Han and Kun Zhang and Hui Xiong},
    year={2025},
    url={https://arxiv.org/abs/2503.01139}
    }
                    </code>
                </pre>
                <br>
            </div>
        </section>
        <footer class="footer">
            <div class="container">
                <!-- <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div> -->
                <div class="columns is-centered">
                    <div class="column is-8">
                        <div class="content">
                            <p>
                                Thanks for the source template from
                                <a href="https://github.com/nerfies/nerfies.github.io">here</a>
                                .
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </footer>
